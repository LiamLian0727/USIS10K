# USIS10K & USIS-SAM
![issues](https://img.shields.io/github/issues/LiamLian0727/USIS10K)
![forks](https://img.shields.io/github/forks/LiamLian0727/USIS10K)
![stars](https://img.shields.io/github/stars/LiamLian0727/USIS10K)
![license](https://img.shields.io/github/license/LiamLian0727/USIS10K)

This repository is the official implementation of "[Diving into Underwater: Segment Anything Model Guided Underwater Salient Instance Segmentation and A Large-scale Dataset]()", authored by Shijie Lian, Ziyi Zhang, Hua Li, Wenjie Li, Laurence Tianruo Yang, Sam Kwong, and Runmin Cong, which has been accepted by ICML2024! ðŸŽ‰ðŸŽ‰ðŸŽ‰

If you found this project useful, please give us a star â­ï¸ or cite us in your paper, this is the greatest support and encouragement for us.

## :rocket: Highlights:
- **USIS10K dataset**: We construct the first large-scale USIS10K dataset for the underwater salient instance segmentation task, which contains 10,632 images and pixel-level annotations of 7 categories. As far as we know, this is the **largest salient instance segmentation dataset** available that simultaneously includes Class-Agnostic and Multi-Class labels.
  
  ![dataset img](figs/dataset_show.png)
- **SOTA performance**: We first attempt to apply SAM to underwater salient instance segmentation and propose USIS-SAM, aiming to improve the segmentation accuracy in complex underwater scenes. Extensive public evaluation criteria and large numbers of experiments verify the effectiveness of our USIS10K dataset and USIS-SAM model.
 
  ![framework_img](figs/framework.png)

## Installation

### Requirements
* Python 3.7+
* Pytorch 2.0+
* [MMDetection](https://mmdetection.readthedocs.io/en/latest/get_started.html) 3.0+
* mmengine
* mmcv>=2.0.0
* CUDA 12.1 or other version

### Installation
<details>
<summary>Environment Installation</summary>

**Step 0**: Download and install [Miniconda](https://docs.conda.io/projects/miniconda/en/latest/index.html) from the official website.

**Step 1**: Create a conda environment and activate it.

```shell
conda create -n usis python=3.19 -y
conda activate usis
```

**Step 2**: Install [PyTorch](https://pytorch.org/get-started/previous-versions/#v212). If you have experience with PyTorch and have already installed it, you can skip to the next section. 

**Step 3**: Install MMEngine, MMCV, and MMDetection using MIM.

```shell
pip install -U openmim
mim install mmengine
mim install "mmcv>=2.0.0"
mim install mmdet
```

</details>

### Datasets

Please create a data folder in your working directory and put USIS10K in it for training or testing, or you can just change the dataset path in the [config file](project/our/config).

    data
      â”œâ”€â”€ USIS10K
      |   â”œâ”€â”€ foreground_annotations
      â”‚   â”‚   â”œâ”€â”€ foreground_train_annotations.json
      â”‚   â”‚   â”œâ”€â”€ foreground_val_annotations.json
      â”‚   â”‚   â”œâ”€â”€ foreground_test_annotations.json
      â”‚   â”œâ”€â”€ multi_class_annotations
      â”‚   â”‚   â”œâ”€â”€ multi_class_train_annotations.json
      â”‚   â”‚   â”œâ”€â”€ multi_class_val_annotations.json
      â”‚   â”‚   â”œâ”€â”€ multi_class_test_annotations.json
      â”‚   â”œâ”€â”€ train
      â”‚   â”‚   â”œâ”€â”€ train_00001.jpg
      â”‚   â”‚   â”œâ”€â”€ ...
      â”‚   â”œâ”€â”€ val
      â”‚   â”‚   â”œâ”€â”€ val_00001.jpg
      â”‚   â”‚   â”œâ”€â”€ ...
      â”‚   â”œâ”€â”€ test
      â”‚   â”‚   â”œâ”€â”€ test_00001.jpg
      â”‚   â”‚   â”œâ”€â”€ ...

you can get our USIS10K dataset in [Baidu Disk]() (pwd:) or [Google Drive]().


